{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sklearn.cluster\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/ericjm/miniconda3/envs/phase-changes/lib/python3.8/site-packages/datasets/arrow_dataset.py:1533: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\", cache_dir=\"data/\")\n",
    "dataset = datasets.load_from_disk(\"data/tinystories_tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_indexes = np.array([0] + list(np.cumsum(dataset[\"preds_len\"])))\n",
    "def loss_idx_to_dataset_idx(idx):\n",
    "    \"\"\"given an idx in range(0, 10658635), return\n",
    "    a sample index in range(0, 20000) and pred-in-sample\n",
    "    index in range(0, 1023). Note token-in-sample idx is\n",
    "    exactly pred-in-sample + 1\"\"\"\n",
    "    sample_index = np.searchsorted(starting_indexes, idx, side=\"right\") - 1\n",
    "    pred_in_sample_index = idx - starting_indexes[sample_index]\n",
    "    return int(sample_index), int(pred_in_sample_index)\n",
    "\n",
    "def get_context(idx):\n",
    "    \"\"\"given idx in range(0, 10658635), return dataset sample\n",
    "    and predicted token index within sample, in range(1, 1024).\"\"\"\n",
    "    sample_index, pred_index = loss_idx_to_dataset_idx(idx)\n",
    "    return dataset[sample_index], pred_index+1\n",
    "\n",
    "def print_context(idx):\n",
    "    \"\"\"\n",
    "    given idx in range(0, 10658635), print prompt preceding the corresponding\n",
    "    prediction, and highlight the predicted token.\n",
    "    \"\"\"\n",
    "    sample, token_idx = get_context(idx)\n",
    "    prompt = sample[\"split_by_token\"][:token_idx]\n",
    "    prompt = \"\".join(prompt)\n",
    "    token = sample[\"split_by_token\"][token_idx]\n",
    "    print(prompt + \"\\033[41m\" + token + \"\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_path = \"data/C-2.pt\"\n",
    "num_clusters = 400\n",
    "eigen_tol = \"auto\"\n",
    "n_init = 30\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_idxs, C = torch.load(matrix_path)\n",
    "C = C.cpu().numpy()\n",
    "C = np.clip(C, -1, 1)\n",
    "C = 1 - np.arccos(C) / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_state)\n",
    "clusters_labels = sklearn.cluster.SpectralClustering(n_clusters=num_clusters, \n",
    "                                                    affinity='precomputed',\n",
    "                                                    eigen_tol=eigen_tol,\n",
    "                                                    n_init=n_init,\n",
    "                                                    random_state=random_state,\n",
    "                                                    assign_labels='kmeans').fit_predict(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4aa550e70648cb9b9dffb29708e393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding contexts:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_frequencies = defaultdict(int)\n",
    "for l in clusters_labels:\n",
    "    label_frequencies[l] += 1\n",
    "\n",
    "labels_sorted_by_freq = sorted(label_frequencies.keys(), key=lambda k: label_frequencies[k], reverse=True)\n",
    "# label_permutation = [labels_sorted_by_freq.index(i) for i in labels_sorted_by_freq]\n",
    "permutation = []\n",
    "indices = defaultdict(list)\n",
    "for i, cls in enumerate(clusters_labels):\n",
    "    indices[cls].append(i)\n",
    "for cls in labels_sorted_by_freq:\n",
    "    permutation.extend(indices[cls])\n",
    "\n",
    "clusters_data = defaultdict(list)\n",
    "for i, label in tqdm(list(enumerate(labels_sorted_by_freq)), desc=\"Finding contexts\"):\n",
    "    for idx_i in indices[label]:\n",
    "        idx = token_idxs[idx_i]\n",
    "        doc, token_idx_within_doc = get_context(idx)\n",
    "        tokens = doc[\"split_by_token\"]\n",
    "        clusters_data[i].append((tokens, token_idx_within_doc))\n",
    "torch.save((clusters_data, clusters_labels), f\"data/{num_clusters}clusters-2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phase-changes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
