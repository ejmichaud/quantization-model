{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import scipy.linalg\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sklearn.cluster\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_unicode(text: str) -> bool:\n",
    "    return any(ord(char) > 127 for char in text)\n",
    "\n",
    "def tokens_to_latex(tokens: List[str], highlight_index=-1) -> str:\n",
    "    latex_code = \"\"\n",
    "    for i, token in enumerate(tokens):\n",
    "        # choose the text that will go inside the \\tok command after {\\strut}\n",
    "        if token == \"\\n\":\n",
    "            latex_text = r\"{\\textbackslash}n\" # some text that represents a newline\n",
    "            # latex_text = \"â†²\" # sadly these aren't working\n",
    "        elif all([c == \" \" for c in token]):\n",
    "            latex_text = r\"\\phantom{\" + \"a\"*len(token) + r\"}\" # some invisible text that represents a space\n",
    "        elif token == \"\\t\":\n",
    "            latex_text = r\"\\phantom{aaaa}\" # some invisible text that represents a tab\n",
    "        else:\n",
    "            latex_text = token.replace(\"_\", r\"\\_\").replace(\"#\", r\"\\#\").replace(\"$\", r\"\\$\").replace(\"%\", r\"\\%\").replace(\"{\", r\"\\{\").replace(\"}\", r\"\\}\")\n",
    "        background_color = \"white\" if i != highlight_index % len(tokens) else \"lightred\"\n",
    "        latex_code += r'\\tok[{}]'.format(background_color) + r'{{\\strut}' + latex_text + '}'\n",
    "        latex_code += r'\\allowbreak '  # Allow line breaks between tokens\n",
    "        if token == \"\\n\":\n",
    "            latex_code += r\"\\\\\"\n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, _ = torch.load(\"data/400clusters-2.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lily and Ben nod. They promise to be careful. They ask mom to read the letter to them. Mom smiles. She reads the letter. It is from grandma. She says she loves them a lot. She sends them kisses and hugs. Lily and Ben are happy. They send kisses and hugs back to grandma. They thank mom for the letter\n"
     ]
    }
   ],
   "source": [
    "cluster_i = 11\n",
    "cluster = clusters[cluster_i]\n",
    "sample_i = 7\n",
    "\n",
    "before = 70\n",
    "after = 0\n",
    "\n",
    "tokens, token_idx = cluster[sample_i]\n",
    "tokens_before = min(before, token_idx)\n",
    "tokens_after = min(after, len(tokens) - token_idx - 1)\n",
    "tokens_slice = tokens[token_idx-tokens_before:token_idx + after + 1]\n",
    "print(\"\".join(tokens_slice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose diverse samples from each cluster\n",
    "i_choices = {\n",
    "    0: 59,\n",
    "    3: 60,\n",
    "    4: 49,\n",
    "    5: 57,\n",
    "    7: 70,\n",
    "}\n",
    "\n",
    "after = 0\n",
    "\n",
    "text = \"\"\n",
    "\n",
    "for j, (i, context_length) in enumerate(i_choices.items()):\n",
    "    before = context_length\n",
    "    tokens, token_idx = cluster[i]\n",
    "    tokens_before = min(before, token_idx)\n",
    "    tokens_after = min(after, len(tokens) - token_idx - 1)\n",
    "    tokens_slice = tokens[token_idx-tokens_before:token_idx + after + 1]\n",
    "    text += tokens_to_latex(tokens_slice)\n",
    "    if j != len(i_choices)-1:\n",
    "        text += \"\\n\\n{\\color{gray}\\\\rule{0.99\\linewidth}{0.5pt}}\\n\\n\"\n",
    "\n",
    "with open(f\"/om2/user/ericjm/the-everything-machine/texts/tinystories/cluster{cluster_i}.tex\", 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time\n"
     ]
    }
   ],
   "source": [
    "cluster_i = 31\n",
    "cluster = clusters[cluster_i]\n",
    "sample_i = 0\n",
    "\n",
    "before = 70\n",
    "after = 0\n",
    "\n",
    "tokens, token_idx = cluster[sample_i]\n",
    "tokens_before = min(before, token_idx)\n",
    "tokens_after = min(after, len(tokens) - token_idx - 1)\n",
    "tokens_slice = tokens[token_idx-tokens_before:token_idx + after + 1]\n",
    "print(\"\".join(tokens_slice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose diverse samples from each cluster\n",
    "i_choices = {\n",
    "    0: 10,\n",
    "    1: 10,\n",
    "    2: 10,\n",
    "    3: 10,\n",
    "    4: 10,\n",
    "    5: 10,\n",
    "    6: 10,\n",
    "    7: 10,\n",
    "}\n",
    "\n",
    "after = 0\n",
    "\n",
    "text = \"\"\n",
    "\n",
    "for j, (i, context_length) in enumerate(i_choices.items()):\n",
    "    before = context_length\n",
    "    tokens, token_idx = cluster[i]\n",
    "    tokens_before = min(before, token_idx)\n",
    "    tokens_after = min(after, len(tokens) - token_idx - 1)\n",
    "    tokens_slice = tokens[token_idx-tokens_before:token_idx + after + 1]\n",
    "    text += tokens_to_latex(tokens_slice)\n",
    "    if j != len(i_choices)-1:\n",
    "        text += \"\\n\\n{\\color{gray}\\\\rule{0.99\\linewidth}{0.5pt}}\\n\\n\"\n",
    "\n",
    "with open(f\"/om2/user/ericjm/the-everything-machine/texts/tinystories/cluster{cluster_i}.tex\", 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next, her mom told Emma to wipe the floor clean. Emma grabbed a cloth and wiped the floor. When she was finished, it was as clean as a new penny.\n",
      "\n",
      "Finally,\n"
     ]
    }
   ],
   "source": [
    "cluster_i = 75\n",
    "cluster = clusters[cluster_i]\n",
    "sample_i = 4\n",
    "\n",
    "before = 38\n",
    "after = 0\n",
    "\n",
    "tokens, token_idx = cluster[sample_i]\n",
    "tokens_before = min(before, token_idx)\n",
    "tokens_after = min(after, len(tokens) - token_idx - 1)\n",
    "tokens_slice = tokens[token_idx-tokens_before:token_idx + after + 1]\n",
    "print(\"\".join(tokens_slice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose diverse samples from each cluster\n",
    "i_choices = {\n",
    "    0: 54,\n",
    "    1: 72,\n",
    "    2: 50,\n",
    "    3: 80,\n",
    "    4: 38\n",
    "}\n",
    "\n",
    "after = 0\n",
    "\n",
    "text = \"\"\n",
    "\n",
    "for j, (i, context_length) in enumerate(i_choices.items()):\n",
    "    before = context_length\n",
    "    tokens, token_idx = cluster[i]\n",
    "    tokens_before = min(before, token_idx)\n",
    "    tokens_after = min(after, len(tokens) - token_idx - 1)\n",
    "    tokens_slice = tokens[token_idx-tokens_before:token_idx + after + 1]\n",
    "    text += tokens_to_latex(tokens_slice)\n",
    "    if j != len(i_choices)-1:\n",
    "        text += \"\\n\\n{\\color{gray}\\\\rule{0.99\\linewidth}{0.5pt}}\\n\\n\"\n",
    "\n",
    "with open(f\"/om2/user/ericjm/the-everything-machine/texts/tinystories/cluster{cluster_i}.tex\", 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearby, her mom was watching and called out, \"Lucy, come here! What's that you have there?\"\n",
      "\n",
      "Lucy proudly held up the hoop and announced, \"\n"
     ]
    }
   ],
   "source": [
    "cluster_i = 77\n",
    "cluster = clusters[cluster_i]\n",
    "sample_i = 11\n",
    "\n",
    "before = 37\n",
    "after = 0\n",
    "\n",
    "tokens, token_idx = cluster[sample_i]\n",
    "tokens_before = min(before, token_idx)\n",
    "tokens_after = min(after, len(tokens) - token_idx - 1)\n",
    "tokens_slice = tokens[token_idx-tokens_before:token_idx + after + 1]\n",
    "print(\"\".join(tokens_slice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose diverse samples from each cluster\n",
    "i_choices = {\n",
    "    0: 41,\n",
    "    3: 49,\n",
    "    4: 51,\n",
    "    5: 67,\n",
    "    11: 37\n",
    "}\n",
    "\n",
    "after = 0\n",
    "\n",
    "text = \"\"\n",
    "\n",
    "for j, (i, context_length) in enumerate(i_choices.items()):\n",
    "    before = context_length\n",
    "    tokens, token_idx = cluster[i]\n",
    "    tokens_before = min(before, token_idx)\n",
    "    tokens_after = min(after, len(tokens) - token_idx - 1)\n",
    "    tokens_slice = tokens[token_idx-tokens_before:token_idx + after + 1]\n",
    "    text += tokens_to_latex(tokens_slice)\n",
    "    if j != len(i_choices)-1:\n",
    "        text += \"\\n\\n{\\color{gray}\\\\rule{0.99\\linewidth}{0.5pt}}\\n\\n\"\n",
    "\n",
    "with open(f\"/om2/user/ericjm/the-everything-machine/texts/tinystories/cluster{cluster_i}.tex\", 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phase-changes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
