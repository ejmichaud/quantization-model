{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import scipy.linalg\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sklearn.cluster\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, GPTNeoXForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/ericjm/miniconda3/envs/phase-changes/lib/python3.8/site-packages/datasets/arrow_dataset.py:1533: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pile_canonical = \"/om/user/ericjm/the_pile/the_pile_test_canonical_200k\"\n",
    "# ----- load the_pile test set -----\n",
    "dataset = datasets.load_from_disk(pile_canonical)\n",
    "\n",
    "def tokenize_sample(sample):\n",
    "    tokens = tokenizer(sample[\"text\"], return_tensors='pt', \n",
    "                        max_length=1024, truncation=True)[\"input_ids\"]\n",
    "    return {\"input_ids\": tokens}\n",
    "\n",
    "starting_indexes = np.array([0] + list(np.cumsum(dataset[\"preds_len\"])))\n",
    "\n",
    "def loss_idx_to_dataset_idx(idx):\n",
    "    \"\"\"given an idx in range(0, 10658635), return\n",
    "    a sample index in range(0, 20000) and pred-in-sample\n",
    "    index in range(0, 1023). Note token-in-sample idx is\n",
    "    exactly pred-in-sample + 1\"\"\"\n",
    "    sample_index = np.searchsorted(starting_indexes, idx, side=\"right\") - 1\n",
    "    pred_in_sample_index = idx - starting_indexes[sample_index]\n",
    "    return int(sample_index), int(pred_in_sample_index)\n",
    "\n",
    "def get_context(idx):\n",
    "    \"\"\"given idx in range(0, 10658635), return dataset sample\n",
    "    and predicted token index within sample, in range(1, 1024).\"\"\"\n",
    "    sample_index, pred_index = loss_idx_to_dataset_idx(idx)\n",
    "    return dataset[sample_index], pred_index+1\n",
    "\n",
    "def print_context(idx, context_length=-1):\n",
    "    \"\"\"\n",
    "    given idx in range(0, 10658635), print prompt preceding the corresponding\n",
    "    prediction, and highlight the predicted token.\n",
    "    \"\"\"\n",
    "    sample, token_idx = get_context(idx)\n",
    "    prompt = sample[\"split_by_token\"][:token_idx]\n",
    "    if context_length > 0:\n",
    "        prompt = prompt[-context_length:]\n",
    "    prompt = \"\".join(prompt)\n",
    "    token = sample[\"split_by_token\"][token_idx]\n",
    "    print(prompt + \"\\033[41m\" + token + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_context(106_396_003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/om/user/ericjm/results/the-everything-machine/clustering-0/clusters_full_more.pkl\", 'rb') as f:\n",
    "    clusters = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs, C, C_abs = torch.load(\"/om/user/ericjm/results/the-everything-machine/clustering-0/full_more.pt\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idxs) # indexes into The Pile test set which were clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_labels, _ = clusters[400]\n",
    "label_frequencies = defaultdict(int)\n",
    "for l in clusters_labels:\n",
    "    label_frequencies[l] += 1\n",
    "\n",
    "labels_sorted_by_freq = sorted(label_frequencies.keys(), key=lambda k: label_frequencies[k], reverse=True)\n",
    "# label_permutation = [labels_sorted_by_freq.index(i) for i in labels_sorted_by_freq]\n",
    "permutation = []\n",
    "indices = defaultdict(list)\n",
    "for i, cls in enumerate(clusters_labels):\n",
    "    indices[cls].append(i)\n",
    "for cls in labels_sorted_by_freq:\n",
    "    permutation.extend(indices[cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_tokens(idx, context_length=100):\n",
    "    sample, token_idx = get_context(idx)\n",
    "    prompt = sample[\"split_by_token\"][:token_idx]\n",
    "    token = sample[\"split_by_token\"][token_idx]\n",
    "    return prompt[-context_length:] + [token]\n",
    "\n",
    "def contains_unicode(text: str) -> bool:\n",
    "    return any(ord(char) > 127 for char in text)\n",
    "\n",
    "def tokens_to_latex(tokens: List[str], highlight_index=-1) -> str:\n",
    "    latex_code = \"\"\n",
    "    for i, token in enumerate(tokens):\n",
    "        # choose the text that will go inside the \\tok command after {\\strut}\n",
    "        if token == \"\\n\":\n",
    "            latex_text = r\"{\\textbackslash}n\" # some text that represents a newline\n",
    "            # latex_text = \"â†²\" # sadly these aren't working\n",
    "        elif all([c == \" \" for c in token]):\n",
    "            latex_text = r\"\\phantom{\" + \"a\"*len(token) + r\"}\" # some invisible text that represents a space\n",
    "        elif token == \"\\t\":\n",
    "            latex_text = r\"\\phantom{aaaa}\" # some invisible text that represents a tab\n",
    "        else:\n",
    "            latex_text = token.replace(\"_\", r\"\\_\").replace(\"#\", r\"\\#\").replace(\"$\", r\"\\$\").replace(\"%\", r\"\\%\").replace(\"{\", r\"\\{\").replace(\"}\", r\"\\}\")\n",
    "        background_color = \"white\" if i != highlight_index % len(tokens) else \"lightred\"\n",
    "        latex_code += r'\\tok[{}]'.format(background_color) + r'{{\\strut}' + latex_text + '}'\n",
    "        latex_code += r'\\allowbreak '  # Allow line breaks between tokens\n",
    "        if token == \"\\n\":\n",
    "            latex_code += r\"\\\\\"\n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose diverse samples from each cluster\n",
    "i_choices = [\n",
    "    0,\n",
    "    3,\n",
    "    4,\n",
    "    6,\n",
    "    # 7, save page space\n",
    "    20\n",
    "]\n",
    "context_lengths = {\n",
    "    0: 99,\n",
    "    3: 100,\n",
    "    4: 102,\n",
    "    6: 100,\n",
    "    # 7: 100, \n",
    "    20: 71\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tQCBlockListMsg          = 0x0a\n",
      "\tGetLatestStatusMsg      = 0x0b\n",
      "\tLatestStatusMsg         = 0x0c\n",
      "\tPrepareBlockHashMsg     = 0x0d\n",
      "\tGetViewChangeMsg        = 0x0e\n",
      "\tPingMsg                 = 0x0\u001b[41mf\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cluster_number = 50\n",
    "cluster_idxs_is = indices[labels_sorted_by_freq[cluster_number]]\n",
    "cluster_idxs = [idxs[cluster_idxs_i] for cluster_idxs_i in cluster_idxs_is]\n",
    "\n",
    "print_context(cluster_idxs[20], context_length=71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "\n",
    "for i in i_choices:\n",
    "    tokens = context_tokens(cluster_idxs[i], context_lengths[i])\n",
    "    text += tokens_to_latex(tokens)\n",
    "    if i != i_choices[-1]:\n",
    "        text += \"\\n\\n{\\color{gray}\\\\rule{0.99\\linewidth}{0.5pt}}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../texts/pile/cluster50.tex\", 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose diverse samples from each cluster\n",
    "i_choices = [\n",
    "    13,\n",
    "    1,\n",
    "    # 2,\n",
    "    # 9,\n",
    "    # 15,\n",
    "    12,\n",
    "    3,\n",
    "    8,\n",
    "]\n",
    "\n",
    "context_lengths = {\n",
    "    13: 97,\n",
    "    1: 73,\n",
    "    # 2: 78,\n",
    "    # 9: 79,\n",
    "    # 15: 73, # really constrained by width here!\n",
    "    12: 75,\n",
    "    3: 46,\n",
    "    8: 77\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!--\n",
      "/**\n",
      " * Copyright (c) 2019, The Android Open Source Project\n",
      " *\n",
      " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      " * you may not use this file except in compliance with the License.\u001b[41m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cluster_number = 100\n",
    "cluster_idxs_is = indices[labels_sorted_by_freq[cluster_number]]\n",
    "cluster_idxs = [idxs[cluster_idxs_i] for cluster_idxs_i in cluster_idxs_is]\n",
    "\n",
    "print_context(cluster_idxs[12], context_length=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "\n",
    "for i in i_choices:\n",
    "    tokens = context_tokens(cluster_idxs[i], context_lengths[i])\n",
    "    text += tokens_to_latex(tokens)\n",
    "    if i != i_choices[-1]:\n",
    "        text += \"\\n\\n{\\color{gray}\\\\rule{0.99\\linewidth}{0.5pt}}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../texts/pile/cluster100.tex\", 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose diverse samples from each cluster\n",
    "i_choices = [\n",
    "    3,\n",
    "    5,\n",
    "    9,\n",
    "    12,\n",
    "]\n",
    "\n",
    "context_lengths = {\n",
    "    3: 75,\n",
    "    5: 75,\n",
    "    9: 75,\n",
    "    12: 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " United States Patent No. 6,073,124 (issued June 6, 2000) (\"the '124 patent\"). Microsoft in turn asserted counterclaims against NCI for infringement of three of its patentsÂ—United States Patent Nos. 5,822,526, 5,999,914 and 5,794,006. Only terms of the '124 patent are presently before the Court; interpretation of claims in Microsoft's patents will be interpreted in a separate Markman hearing to be held on November 15\u001b[41m,\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cluster_number = 146\n",
    "cluster_idxs_is = indices[labels_sorted_by_freq[cluster_number]]\n",
    "cluster_idxs = [idxs[cluster_idxs_i] for cluster_idxs_i in cluster_idxs_is]\n",
    "\n",
    "print_context(cluster_idxs[12], context_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "\n",
    "for i in i_choices:\n",
    "    tokens = context_tokens(cluster_idxs[i], context_lengths[i])\n",
    "    text += tokens_to_latex(tokens)\n",
    "    if i != i_choices[-1]:\n",
    "        text += \"\\n\\n{\\color{gray}\\\\rule{0.99\\linewidth}{0.5pt}}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../texts/pile/cluster146.tex\", 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose diverse samples from each cluster\n",
    "i_choices = {\n",
    "    0: 100,\n",
    "    1: 40,\n",
    "    3: 96,\n",
    "    5: 16,\n",
    "    6: 24,\n",
    "    7: 38\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In 1954, the couple published Living the Good Life which inspired many young, educated Americans to create simpler, rural lifestyles and the back-to-the-land movement of the 1960\u001b[41ms\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cluster_number = 269\n",
    "cluster_idxs_is = indices[labels_sorted_by_freq[cluster_number]]\n",
    "cluster_idxs = [idxs[cluster_idxs_i] for cluster_idxs_i in cluster_idxs_is]\n",
    "\n",
    "print_context(cluster_idxs[7], context_length=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "\n",
    "for j, (i, context_length) in enumerate(i_choices.items()):\n",
    "    tokens = context_tokens(cluster_idxs[i], context_length)\n",
    "    text += tokens_to_latex(tokens)\n",
    "    if j != len(i_choices)-1:\n",
    "        text += \"\\n\\n{\\color{gray}\\\\rule{0.99\\linewidth}{0.5pt}}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../texts/pile/cluster269.tex\", 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose diverse samples from each cluster\n",
    "i_choices = {\n",
    "    2: 100,\n",
    "    3: 100,\n",
    "    5: 29\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See: http://jsfiddle.net/mWFGZ/1/\n",
      "html, body {\n",
      "    margin: 0;\n",
      "    padding\u001b[41m:\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cluster_number = 278\n",
    "cluster_idxs_is = indices[labels_sorted_by_freq[cluster_number]]\n",
    "cluster_idxs = [idxs[cluster_idxs_i] for cluster_idxs_i in cluster_idxs_is]\n",
    "\n",
    "print_context(cluster_idxs[5], context_length=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "\n",
    "for j, (i, context_length) in enumerate(i_choices.items()):\n",
    "    tokens = context_tokens(cluster_idxs[i], context_length)\n",
    "    text += tokens_to_latex(tokens)\n",
    "    if j != len(i_choices)-1:\n",
    "        text += \"\\n\\n{\\color{gray}\\\\rule{0.99\\linewidth}{0.5pt}}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../texts/pile/cluster278.tex\", 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose diverse samples from each cluster\n",
    "i_choices = {\n",
    "    0: 26,\n",
    "    1: 47,\n",
    "    2: 100,\n",
    "    5: 80\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But as citizens, our responsibility is to look beyond the anecdote. We journalists try to make sure that if a tree falls in the forest, it wonâ€™t go unnoticed. Still, if we get so taken by the trees that we donâ€™t see the forest, weâ€™ll all be lost.\n",
      "\n",
      "Rex Smith is editor of the Times Union. Share your thoughts at http\u001b[41m://\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cluster_number = 292\n",
    "cluster_idxs_is = indices[labels_sorted_by_freq[cluster_number]]\n",
    "cluster_idxs = [idxs[cluster_idxs_i] for cluster_idxs_i in cluster_idxs_is]\n",
    "\n",
    "print_context(cluster_idxs[5], context_length=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "\n",
    "for j, (i, context_length) in enumerate(i_choices.items()):\n",
    "    tokens = context_tokens(cluster_idxs[i], context_length)\n",
    "    text += tokens_to_latex(tokens)\n",
    "    if j != len(i_choices)-1:\n",
    "        text += \"\\n\\n{\\color{gray}\\\\rule{0.99\\linewidth}{0.5pt}}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../texts/pile/cluster292.tex\", 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\u2009'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\\u2009'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************\n",
      "  The â€˜â€˜officially releasedâ€™â€™ date that appears near the\n",
      "beginning of each opinion is the date the opinion will\n",
      "be published in the Connecticut Law Journal or the\n",
      "date it was released as a slip opinion. The operative\n",
      "date for the beginning of all time periods for filing\n",
      "postopinion motions and petitions for certification is\n",
      "the â€˜â€˜officially releasedâ€™â€™ date appearing in the opinion.\n",
      "In no event will any such motions be accepted before\n",
      "the â€˜â€˜officially releasedâ€™â€™ date.\n",
      "  All opinions are subject to modification and technical\n",
      "correction prior to official publication in the Connecti-\n",
      "cut Reports and Connecticut Appellate Reports. In the\n",
      "event of discrepancies between the electronic version\n",
      "of an opinion and the print version appearing in the\n",
      "Connecticut Law Journal and subsequently in the Con-\n",
      "necticut Reports or Connecticut Appellate Reports, the\n",
      "latest print version is to be considered authoritative.\n",
      "  The syllabus and procedural history accompanying\n",
      "the opinion as it appears on the Commission on Official\n",
      "Legal Publications Electronic Bulletin Board Service\n",
      "and in the Connecticut Law Journal and bound volumes\n",
      "of official reports are copyrighted by the Secretary of\n",
      "the State, State of Connecticut, and may not be repro-\n",
      "duced and distributed without the express written per-\n",
      "mission of the Commission on Official Legal\n",
      "Publications, Judicial Branch, State of Connecticut.\n",
      "******************************************************\n",
      "\f              STATE v. TAYLOR G.â€”CONCURRENCE\n",
      "\n",
      "   PALMER, J., concurring. I agree with and join the\n",
      "majority opinion because I am not persuaded that the\n",
      "mandatory minimum sentences imposed on the defen-\n",
      "dant, Taylor G., violated his eighth amendment right to\n",
      "an individualized sentencing decision that takes into\n",
      "account the youth and immaturity of a person who, like\n",
      "the defendant, commits a crime or crimes while under\n",
      "the age of eighteen. In fact, as the majority notes, there\n",
      "appears to be no case in which any court, state or\n",
      "federal, has held that the eighth amendment categori-\n",
      "cally bars the imposition of a mandatory minimum sen-\n",
      "tence on a juvenile. But cf. State v. Lyle, 854 N.W.2d\n",
      "378, 386, 400 (Iowa 2014) (recognizing such prohibition\n",
      "under Iowa state constitution but acknowledging that\n",
      "â€˜â€˜no other court in the nation has held that its constitu-\n",
      "tion or the [f]ederal [c]onstitution prohibits a statutory\n",
      "schema that prescribes a mandatory minimum sentence\n",
      "for a juvenile offenderâ€™â€™). Furthermore, in the present\n",
      "case, the defendant has not raised a claim under the\n",
      "Connecticut constitution.\n",
      "   I write separately, however, only to point out that,\n",
      "although the federal constitution does not prevent the\n",
      "legislature from subjecting juvenile offenders to certain\n",
      "kinds of mandatory minimum sentences, the legislature\n",
      "may wish to revisit the question of whether such manda-\n",
      "tory prison terms are appropriate for juveniles, as a\n",
      "matter of sound public policy, in light of the marked\n",
      "differences between juveniles and adults. The United\n",
      "States Supreme Court recently reiterated these differ-\n",
      "ences in Miller v. Alabama,         U.S.     , 132 S. Ct. 2455,\n",
      "183 L. Ed. 2d 407 (2012), explaining that, â€˜â€˜[b]ecause\n",
      "juveniles have diminished culpability and greater pros-\n",
      "pects for reform [than adults]... they are less deserv-\n",
      "ing of the most severe punishments.â€™â€™ (Internal quota-\n",
      "tion marks omitted.) Id., 2464. As the court in Miller\n",
      "further explained, this conclusion is founded on â€˜â€˜three\n",
      "significant gaps between juveniles and adults. First,\n",
      "children have a lack of maturity and an underdeveloped\n",
      "sense of responsibility, leading to recklessness, impul-\n",
      "sivity, and heedless risk-taking.... Second, children\n",
      "are more vulnerable... to negative influences and\n",
      "outside pressures, including from their family and\n",
      "peers; they have limited contro[l] over their own envi-\u001b[41m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cluster_number = 100\n",
    "cluster_idxs_is = indices[labels_sorted_by_freq[cluster_number]]\n",
    "cluster_idxs = [idxs[cluster_idxs_i] for cluster_idxs_i in cluster_idxs_is]\n",
    "\n",
    "print_context(cluster_idxs[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "\n",
    "for i in range(6):\n",
    "    tokens = context_tokens(cluster_idxs[i], 50)\n",
    "    text += tokens_to_latex(tokens)\n",
    "    if i != 6-1:\n",
    "        text += \"\\n\\n{\\color{gray}\\\\rule{0.99\\linewidth}{0.5pt}}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/om2/user/ericjm/the-everything-machine/texts/pile/cluster100.tex\", 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def context_str(idx):\n",
    "    sample, token_idx = get_context(idx)\n",
    "    prompt = sample[\"split_by_token\"][:token_idx]\n",
    "    prompt = \"\".join(prompt)\n",
    "    token = sample[\"split_by_token\"][token_idx]\n",
    "    if len(prompt) > 300:\n",
    "        prompt = \"...\" + prompt[-300:]\n",
    "    return prompt + \"<|\" + token + \"|>\"\n",
    "\n",
    "# create directory at `/om/user/ericjm/results/the-everything-machine/clustering-0/full/00500`\n",
    "clustersdir = Path(\"/om/user/ericjm/results/the-everything-machine/clustering-0/full_more/00500\")\n",
    "clustersdir.mkdir(parents=True, exist_ok=True) # override if already exists\n",
    "\n",
    "for i, label in tqdm(list(enumerate(labels_sorted_by_freq))):\n",
    "    # create subdirectory of cluster\n",
    "    clusterdir = clustersdir / Path((5-len(str(i)))*\"0\"+str(i))\n",
    "    clusterdir.mkdir(exist_ok=True)\n",
    "    with open(os.path.join(clusterdir, \"prompts.txt\"), \"w\") as f:\n",
    "        for idx_i in indices[label]:\n",
    "            idx = idxs[idx_i]\n",
    "            f.write(context_str(idx))\n",
    "            f.write(\"\\n\"+\"-\"*40+\"\\n\")\n",
    "    plt.figure()\n",
    "    for idx_i in indices[label]:\n",
    "        idx = idxs[idx_i]\n",
    "        plt.plot(list(range(1000, 144000, 1000)), timeseries19m[idx], color='black', alpha=0.1)\n",
    "    plt.yscale('log')\n",
    "    plt.savefig(os.path.join(clusterdir, \"trajectories.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phase-changes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
